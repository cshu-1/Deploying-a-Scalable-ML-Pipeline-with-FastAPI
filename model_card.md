# Model Card

For additional information see the Model Card paper: https://arxiv.org/pdf/1810.03993.pdf

## Model Details

The model is a Random Forest Classifier implemented using scikit-learn with hyperparameter optimization through Grid Search Cross-Validation. This supervised learning model was developed for binary classification tasks to predict income levels based on demographic and employment characteristics. The model utilizes ensemble learning techniques with decision trees as base estimators to achieve robust performance across different data distributions. Hyperparameter tuning was performed using 5-fold cross-validation with a grid search across multiple parameters including the number of estimators (100, 200), maximum depth (10, 20, None), minimum samples split (2, 5), and minimum samples leaf (1, 2). The final model represents the best-performing configuration based on F1-score optimization during the cross-validation process.

## Intended Use

This model is designed for binary classification to predict whether an individual's annual income exceeds $50,000 based on demographic and employment characteristics from census data. The primary intended use is for research purposes, educational demonstrations, and academic analysis of socioeconomic patterns in income distribution. The model can serve as a baseline for comparative studies in machine learning fairness research and algorithmic bias detection. It is specifically intended for users who need to understand income prediction patterns across different demographic groups and want to analyze potential disparities in model performance. The model should be used by researchers, data scientists, and students working on projects related to income inequality, demographic analysis, or machine learning fairness studies.

## Training Data

The training data consists of census income data derived from the 1994 Census database, commonly known as the Adult dataset from the UCI Machine Learning Repository. The dataset contains demographic and employment information for individuals, with the target variable being a binary classification of whether annual income exceeds $50,000. The training set was created using an 80/20 stratified split, resulting in approximately 26,000 training instances from the original 32,561 records. The dataset includes eight categorical features: workclass, education, marital status, occupation, relationship, race, sex, and native country. Each categorical feature was processed using one-hot encoding to convert categorical variables into numerical representations suitable for machine learning algorithms. The stratified split ensures that the proportion of individuals in each income category is maintained between the training and test sets, preventing class imbalance issues during model training.

## Evaluation Data

The evaluation data consists of the remaining 20% of the original census dataset, containing approximately 6,500 test instances. The test set was created using stratified sampling to ensure representative distribution of the target classes, maintaining the same proportion of high-income and low-income individuals as in the original dataset. The same preprocessing pipeline used for training data was applied to the evaluation data, including one-hot encoding for categorical features and label binarization for the target variable. The evaluation approach includes both overall model performance assessment and detailed slice-based analysis across each categorical feature to identify potential performance disparities across different demographic groups. This comprehensive evaluation strategy allows for the detection of bias and ensures the model's behavior is well-understood across various population segments.

## Metrics

The model performance is evaluated using three key classification metrics: precision, recall, and F1-score. Precision measures the proportion of positive predictions that are actually correct, indicating the model's ability to avoid false positives. Recall measures the proportion of actual positive cases that are correctly identified, indicating the model's ability to find all positive instances. The F1-score provides a harmonic mean of precision and recall, offering a balanced assessment of model performance. On the hold-out test set, the model achieved a precision of 0.7807, meaning that 78.07% of individuals predicted to earn more than $50,000 actually do earn more than $50,000. The model achieved a recall of 0.6333, indicating that it correctly identifies 63.33% of all individuals who actually earn more than $50,000. The F1-score of 0.6993 represents the balanced performance between precision and recall. These metrics indicate that while the model is relatively conservative in its positive predictions (high precision), it misses a significant portion of high-income individuals (moderate recall).

## Ethical Considerations

This model presents several important ethical considerations that must be addressed before deployment or use in any decision-making context. The model has been trained on historical census data from 1994, which may perpetuate historical biases and inequalities present in society at that time. Performance analysis across different demographic slices reveals potential disparities in model accuracy across protected groups, including variations based on race, sex, and native country. These performance disparities could lead to discriminatory outcomes if the model were used in high-stakes applications such as hiring, lending, or social services. The model's moderate recall rate means it may systematically underpredict high-income status for certain demographic groups, potentially disadvantaging those populations. Additionally, the binary classification approach oversimplifies complex socioeconomic realities and may not capture the full spectrum of economic circumstances. Users must consider the potential for algorithmic bias and implement appropriate fairness measures if deploying this model in any application that affects individuals' opportunities or rights.

## Caveats and Recommendations

Several important caveats must be considered when using this model. The model's recall performance of 63.33% indicates that it fails to identify approximately 37% of individuals who actually earn more than $50,000, which represents a significant limitation for applications requiring high sensitivity. The training data from 1994 may not accurately reflect current economic conditions, employment patterns, or demographic distributions, potentially reducing the model's relevance for contemporary applications. Performance variations across demographic groups suggest that the model may exhibit bias against certain populations, requiring careful monitoring and potential mitigation strategies. The model should not be used as the sole basis for any decisions that could impact individuals' opportunities, rights, or access to services. For research and educational purposes, users should complement this model with additional bias detection techniques and fairness-aware machine learning approaches. Regular model retraining with updated data is recommended to maintain relevance and accuracy. If deployed in any practical application, continuous monitoring of performance across demographic groups is essential, along with human oversight and the implementation of appropriate bias mitigation techniques. Consider exploring ensemble methods or alternative algorithms to improve recall performance and reduce demographic disparities.